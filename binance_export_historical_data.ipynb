{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import io\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define date and url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'BTCUSD'\n",
    "type = 'spot_index'\n",
    "base_url = 'https://public.bybit.com/'\n",
    "date = '2019-10-01'\n",
    "data_extension = '.csv.gz'\n",
    "file_name = index + date + '_index_price' + data_extension\n",
    "url = base_url + type + '/' + index + '/'  + file_name\n",
    "compressed_path = 'data/raw/compressed/'\n",
    "extracted_path = 'data/raw/extracted/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-45-ed6f835d45c1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-45-ed6f835d45c1>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    https://public.bybit.com/spot_index/BTCUSD/BTCUSD2019-10-01_index_price.csv.gz\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://public.bybit.com/spot_index/BTCUSD/BTCUSD2019-10-01_index_price.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of dates from the data source page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dates = base_url + type + '/' + index + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url_dates, allow_redirects=True)\n",
    "dates_content = r.text\n",
    "dates_content = dates_content.split('<li>')\n",
    "dates_content = [row.split('\"')[1] for row in dates_content]\n",
    "dates_content = dates_content[1:]\n",
    "dates = [row.split('BTCUSD')[1].split('_index')[0] for row in dates_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = pd.DataFrame()\n",
    "df_dates['date'] = dates\n",
    "df_dates['date'] = pd.to_datetime(df_dates['date'])\n",
    "df_dates['exists'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the window the data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = px.data.stocks()\n",
    "fig = px.scatter(df_dates, x='date', y='exists')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get content from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    content = r.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the content into defined path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_content(compressed_path, content, file_name):\n",
    "    open(os.path.join(compressed_path,file_name), 'wb').write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and write content for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_dates(*args):\n",
    "    for date in dates:\n",
    "        file_name = index + date + '_index_price' + data_extension\n",
    "        url = base_url + type + '/' + index + '/'  + file_name\n",
    "        content = get_content(url)\n",
    "        write_content(compressed_path, content, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'dates' : dates,\n",
    "        'index' : index,\n",
    "        'data_extension' : data_extension,\n",
    "        'base_url' : base_url,\n",
    "        'file_name' : file_name,\n",
    "        'compressed_path' : compressed_path}\n",
    "download_all_dates(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_gzip(compressed_path, extracted_path, file_name):\n",
    "    with gzip.open(os.path.join(compressed_path, file_name), 'rb') as f_in:\n",
    "        file_name = file_name.replace('.gz','')\n",
    "        with open(os.path.join(extracted_path,file_name), 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_files_in_path(*args):\n",
    "    file_names = [file for file in os.listdir(compressed_path) if file.endswith(\".gz\")]\n",
    "    for file_name in file_names:\n",
    "        unzip_gzip(compressed_path, extracted_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'dates' : dates,\n",
    "        'index' : index,\n",
    "        'data_extension' : data_extension,\n",
    "        'base_url' : base_url,\n",
    "        'compressed_path' : compressed_path}\n",
    "unzip_files_in_path(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read extracted path and append data into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csvs_to_dataframe(extracted_path):\n",
    "    file_names = [file for file in os.listdir(extracted_path) if file.endswith(\".csv\")]#\n",
    "    file_paths = [os.path.join(extracted_path, file_name) for file_name in file_names]\n",
    "    data = pd.concat([pd.read_csv(file_path) for file_path in file_paths])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = concat_csvs_to_dataframe(extracted_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the concatenated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_concat_data():\n",
    "    concat_path = extracted_path.replace('extracted', 'concatenated')\n",
    "    data.sort_values(by='start_at', ascending=True, inplace=True)\n",
    "    start_date = datetime.fromtimestamp(data['start_at'].iloc[0]).date()\n",
    "    end_date = datetime.fromtimestamp(data['start_at'].iloc[-1]).date()\n",
    "    data_name = index + '_' + str(start_date) + '_' + str(end_date) + '_' + type + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(concat_path,data_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
